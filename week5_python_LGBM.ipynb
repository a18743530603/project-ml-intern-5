{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87a07e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== LightGBM CV Result =====\n",
      "每折分数: [0.96491228 0.97368421 0.96491228 0.99122807 0.95575221]\n",
      "平均分数: 0.9700978108989287\n",
      "标准差: 0.011991044682000119\n",
      "\n",
      "===== RandomForest CV Result =====\n",
      "每折分数: [0.95614035 0.96491228 0.93859649 0.96491228 0.96460177]\n",
      "平均分数: 0.9578326346840551\n",
      "标准差: 0.010187806503281693\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# 1️⃣ 载入示例数据\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "# 2️⃣ 定义模型（关闭 LightGBM 日志）\n",
    "lgbm = LGBMClassifier(random_state=42, verbose=-1)\n",
    "rf   = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 3️⃣ 5-Fold 交叉验证\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "lgbm_scores = cross_val_score(lgbm, X, y, cv=cv, scoring=\"accuracy\")\n",
    "rf_scores   = cross_val_score(rf, X, y, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "# 4️⃣ 输出详细结果\n",
    "print(\"===== LightGBM CV Result =====\")\n",
    "print(\"每折分数:\", lgbm_scores)\n",
    "print(\"平均分数:\", np.mean(lgbm_scores))\n",
    "print(\"标准差:\", np.std(lgbm_scores))\n",
    "\n",
    "print(\"\\n===== RandomForest CV Result =====\")\n",
    "print(\"每折分数:\", rf_scores)\n",
    "print(\"平均分数:\", np.mean(rf_scores))\n",
    "print(\"标准差:\", np.std(rf_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01e2ee",
   "metadata": {},
   "source": [
    "在 5 折交叉验证下，LightGBM 的平均准确率略高于 RandomForest。\n",
    "可能原因：\n",
    "\n",
    "模型表达能力：LightGBM 使用基于梯度提升的 boosting 框架，能更好地捕捉复杂特征间关系；而随机森林是 bagging 思想，更多依赖特征随机子集的投票，拟合能力稍弱。\n",
    "\n",
    "特征利用：LightGBM 会进行特征分裂点优化和直方图近似分裂，能更高效地利用特征信息。\n",
    "\n",
    "偏差-方差权衡：Boosting 逐步减少偏差，通常在 tabular 数据上比单纯降低方差的 bagging 更强。\n",
    "\n",
    "👉 总体来说，LightGBM baseline 在大多数结构化数据任务上通常比 RandomForest 表现更好。\n",
    "随机森林：一群独立的“弱学习器”投票，思想偏向“民主”。\n",
    "\n",
    "LightGBM/GBDT：一棵树一棵树“接力修正”，思想偏向“迭代改进”。\n",
    "\n",
    "类比：\n",
    "\n",
    "随机森林 = “很多同学各自做题，最后投票选答案”。\n",
    "\n",
    "LightGBM = “一个同学做题，错了老师一点点纠正，逐步把答案修正得更准”。\n",
    "\n",
    "✅ 所以，LightGBM 并不是随机森林的加强版，而是另一类集成方法（Boosting），和随机森林（Bagging）属于两种不同思路。\n",
    "不过在结构化数据任务上，LightGBM 往往确实比随机森林表现更好。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
